+++
date = "2017-12-30T19:02:37+01:00"
description = "Training vs Testing"
draft = false
tags = ["Machine Learning","NTU"]
title =  "NTU Machine Learning - Lec5"
topics = ["Machine Learning Foundation"]
+++

ä¸Šä¸€è¬›æåˆ°äº†åœ¨ hypothesis set <span>$\mathcal{H}$</span> ç‚ºæœ‰é™ï¼Œä¸”sample size <span>$|\mathcal{D}|$</span> è¶³å¤ å¤§çš„æƒ…æ³ä¸‹ï¼Œæ˜¯ PAC-learnable çš„ã€‚ä½†ç•¶ <span>$|\mathcal{H}| \, \rightarrow \, \infty$</span>çš„æ™‚å€™å‘¢ï¼Ÿ (e.g 2D linear perceptron)

<!--more-->

## Recap of Feasibility of Learning

1. <span>$E_o(g) \approx E_i(g)$</span> ?
2. <span>$E_i(g) \rightarrow 0$</span> ?

Hoeffding Ineq. å°æ–¼å†è¤‡é›œçš„ ground truth function <span>$f$</span> åŠ hypothesis function <span>$h$</span> å‡æ˜¯æˆç«‹çš„ï¼Œ1. æ“šæ­¤å¿…æ˜¯æ­£ç¢ºï¼Œä½†é€™åƒ…èƒ½ verify æˆ‘å€‘å¾—åˆ°çš„çµæœï¼Œé‚„æ˜¯æ²’æœ‰å‘Šè¨´æˆ‘å€‘åœ¨è¤‡é›œçš„ <span>$f$</span> (usually ä¸èƒ½åªä¾é ä¸€å€‹ hypothesis candidate <span>$h$</span>ï¼Œè€Œæ˜¯å¿…é ˆå¾ size ç„¡é™å¤§çš„ hypothesis set <span>$\mathcal{H}$</span> å»æŒ‘é¸)ä¸‹ï¼Œå­¸ç¿’æ˜¯å¦å¯è¡Œï¼Ÿ

## Some observation: Does the Union Bound too loose?

From å‰ä¸€è¬›æœ€å¾Œï¼Œ

<div>
\[

\Pr_D[\text{BAD} \, \text{for} \, \textcolor{orange}{\mathcal{H}}] \leq 2 \, M \, \exp(-2 \epsilon^2 N)
\]
</div>

å…¶ä¸­ï¼Œ<span>$M$</span> æ˜¯ä¾†è‡ª Union Bound å°‡å„å€‹ <span>$\underset{D}{\Pr}\,[\text{BAD} \, \text{for} \, \textcolor{orange}{h_n}]$</span> åšåŠ ç¸½ï¼Œç­‰è™Ÿæˆç«‹æ–¼äº‹ä»¶å½¼æ­¤äº’æ–¥ã€‚

äº‹ä»¶å½¼æ­¤äº’æ–¥ï¼Ÿä¹Ÿå°±æ˜¯èªªæœƒè®“ <span>$h_n$</span> å£æ‰çš„ <span>$\mathcal{D}$</span> å„è‡ªä¸åŒï¼Œä½†æƒ³æƒ³é€™å…¶å¯¦ä¸åˆç†ã€‚å°±æ‹¿ perceptron ä¾†èªªå¥½äº†ï¼Œè‹¥ <span>$h_1 \approx h_2$</span> ï¼Œå¹¾ä½•ä¸Šä¾†èªªï¼Œé€™å…©å€‹ hyperplane å…¶å¯¦æ˜¯éå¸¸**é è¿‘**çš„ï¼Œå°å¤§éƒ¨åˆ†çš„æ•¸æ“šé»ï¼Œå‡æœƒçµ¦å‡ºä¸€æ¨£çš„ perdiction ï¼Œæ‰€ä»¥æœƒè®“ <span>$h_1$</span> å£æ‰çš„ <span>$\mathcal{D}$</span> ï¼Œä¹Ÿ **probably** æœƒè®“ <span>$h_2$</span> å£æ‰ã€‚

## Effective number of Hypotheses

é¦–å…ˆï¼Œæˆ‘å€‘å…ˆå°‡ <span>$h$</span> å€‘åšé©ç•¶çš„åˆ†ç¾¤ï¼Œå¾æ•¸æ“šé»çš„è§’åº¦ä¾†çœ‹ï¼Œæœƒ predict å‡ºç›¸åŒçµæœçš„ hypothesis set è¦–ç‚º**ç›¸åŒ**çš„ä¸€ç¾¤ (è©³ç´°ç¯„ä¾‹å¯ä»¥çœ‹è¬›ç¾©ğŸ‘€)ï¼Œå° binary classification ä¾†èªªï¼Œæ¯ä¸€ç¾¤åˆç¨±ç‚ºä¸€å€‹äºŒå…ƒåˆ†é¡å™¨ (*dichotomy*)ã€‚\\
çµ¦å®šæ•¸æ“šé» <span>$\mathbf{x}_1 \sim \mathbf{x}_N$</span>ï¼Œæˆ‘å€‘å¯ä»¥å®šç¾©ä¸åŒçš„ dichotomy ï¼Œ <span>$\mathcal{H}(\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_N)$</span> ç‚ºé€™äº› dichotomies çš„é›†åˆ(è·ŸåŸå…ˆçš„ <span>$\mathcal{H}$</span> æœ‰ä½•ä¸åŒå‘¢ï¼Ÿå¯ä»¥æƒ³æˆè‹¥ <span>$h_i, h_j$</span> åœ¨ training data ä¸Šçµæœç›¸åŒï¼Œå‰‡åªæœƒå°æ‡‰åˆ°ç•¶ä¸­çš„ **ä¸€å€‹** dichotomy)ã€‚è€Œæˆ‘å€‘æƒ³ä»¥é€™å€‹é›†åˆçš„å¤§å° (ä¹Ÿå°±æ˜¯åˆ†ç¾¤æ•¸)ï¼Œå»å–ä»£åŸå…ˆçš„ <span>$M$</span> ã€‚

### Growth Function <span>$m_H$</span>

å¯ä»¥ç™¼ç¾ï¼Œéš¨è‘— sample çš„ <span>$\mathcal{D}$</span> ä¸åŒï¼Œåˆ†ç¾¤çš„çµæœä¹Ÿæœƒä¸åŒï¼Œ
in order to generalization ï¼Œæˆ‘å€‘å®šç¾© growth function <span>$m_H$</span> ç‚ºç•¶ä¸­
çš„ upper bound ï¼Œä¹Ÿæ˜¯æˆ‘å€‘ä¹‹å¾Œè¦æ‹¿ä¾†å–ä»£ <span>$M$</span> çš„é‡ã€‚

``$$
m_H(N) = \underset{\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_N \in \mathcal{X}}{\max} |\mathcal{H}(\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_N)|
$$``

å…¶ä¸­ <span>$m_H(N) \leq 2^N$</span> (which is easy to see)

## <span>$m_H$</span> is POLY?

å›åˆ°æœ€ä¸Šæ–¹çš„å¼å­ï¼Œéš¨è‘— sample size <span>$N$</span> çš„å¢é•·ï¼Œå…¶å£“ä½å£äº‹ç™¼ç”Ÿæ©Ÿç‡çš„èƒ½åŠ›æ˜¯ **EXP** ï¼Œæ‰€ä»¥æˆ‘å€‘åªè¦èƒ½è­‰æ˜ <span>$m_H$</span> ç‚º **POLY** ï¼Œä¾¿å¯ä»¥ claim èªªï¼Œåœ¨ <span>$N$</span> è¶³å¤ å¤§çš„æƒ…æ³ä¸‹ï¼Œ PAC-learnable (even <span>$\mathcal{H}$</span> is infinite)!

å¯ä»¥åœ¨è¬›ç¾©çœ‹åˆ°å¹¾å€‹ç°¡å–®çš„ä¾‹å­(ğŸ‘€ 1D perceptron, 1D interval, 2D contour)ï¼Œä¸¦æ±‚å‡ºå…¶ growth function çš„ analytical formï¼Œä½†å¾ˆå¤šæ™‚å€™è¦å¯«ä¸‹é€™å€‹ form ä¸¦ä¸é‚£éº¼ç°¡å–®ï¼Œç„¶è€Œï¼Œå…¶å¯¦æˆ‘å€‘é—œå¿ƒçš„åªæ˜¯å®ƒçš„ orderï¼Œæˆ–è€…èªªä»–æ˜¯å¦ç‚º **POLY** ç½·äº†ã€‚ç‚ºäº†æ–¹ä¾¿è¨è«–ï¼Œä»¥ä¸‹åšå¹¾å€‹å®šç¾©ã€‚

### Shatter

<div>
\[
\text{If} \: \mathcal{H} \: \text{can \textbf{shatter} N points} \Leftrightarrow m_H(N) = 2^N
\]
</div>

è§£é‡‹æ˜¯èªªï¼Œæ‰€æ“æœ‰çš„ dichotomies ï¼Œå¯ä»¥æ‡‰ä»˜training dataä¸­æ‰€æœ‰å¯èƒ½çš„åˆ†ç¾¤æƒ…æ³ã€‚\\
(<span>$\exists \, h $</span>  s.t <span>$h(\mathbf{x}_i) = f(\mathbf{x}_i) \; \forall i=1 \sim N$</span>)ï¼Œç›´è¦ºä¾†æƒ³ï¼Œé€™ä»£è¡¨äº†é€™å€‹ Hypothesis set å¾ˆå¼·ï¼Œä½†åŒæ™‚ä¹Ÿè¡¨ç¤ºäº†éœ€è¦æœç´¢çš„æ•¸é‡å¾ˆå¤šï¼Œå‘ˆç¾åœ¨ growth function ç‚º **EXP** ã€‚


### Break Point

ç„¶è€Œï¼Œå¾ˆå¤šæ™‚å€™æˆ‘å€‘å°è³‡æ–™æœ‰äº›æ´è¦‹ï¼ŒçŸ¥é“ä»–æ»¿è¶³æŸç¨®æ€§è³ªï¼Œä¸ä¸€å®šè¦æ‰¾é‚£ç¨®å¯ä»¥æ‡‰ä»˜æ‰€æœ‰æƒ…æ³çš„ Hypothesis setï¼Œæ‹¿ Linear perceptron æ‰€è™•ç†çš„å°è±¡ç‚ºä¾‹ï¼Œæˆ‘å€‘å‡è¨­è³‡æ–™æ˜¯ç·šæ€§å¯åˆ†ï¼Œé‚£éº¼ä¾¿ä¸éœ€è¦ç”¨åˆ° convex set é€™éº¼å¼·çš„ Hypothesis set äº† (æ‰€è¬‚æ®ºé›ç„‰ç”¨ç‰›åˆ€)

<div>
\[
\text{If no data set of size } \, k \, \text{can be \textbf{shattered} by} \, \mathcal{H}, \;  k \, \text{is the \textbf{break point} for } \, \mathcal{H}
\]
</div>


ç°¡å–®ä¾†èªªå°±æ˜¯ï¼Œ <span>$\exists \; k \in \mathbb{N} \, s.t. \, m_H(k) < 2^{k}$</span> ,which is **POLY**\\
(ç•¶ <span>$N \geq k$</span> æ™‚ï¼Œé–‹å§‹å‡ºç¾ <span>$\mathcal{H}$</span> ç„¡æ³•è™•ç†ï¼Œæˆ–è€…èªªä¸è€ƒæ…®çš„æƒ…æ³)

## Reference

* [æ—è»’ç”°è€å¸«çš„è¬›ç¾©](https://www.csie.ntu.edu.tw/~htlin/course/ml15fall/doc/05_handout.pdf)
